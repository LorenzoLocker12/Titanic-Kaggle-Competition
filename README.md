# Titanic - Machine Learning from Disaster ğŸš¢

Welcome to my repository for the **Titanic - Machine Learning from Disaster** Kaggle competition! This project was my first foray into Kaggle competitions, and I'm excited to share my work with you. Despite being new to Kaggle, I achieved a **Top 17% ranking**, which motivates me to keep learning and improving in the field of data science. 

---

## ğŸ“ Overview

The Titanic competition is a classic beginner-friendly challenge in machine learning. The goal is to predict whether a passenger survived the Titanic disaster based on features such as:
- **Pclass**: Ticket class (1st, 2nd, or 3rd)
- **Sex**: Gender of the passenger
- **Age**: Passenger's age
- **SibSp**: Number of siblings/spouses aboard
- **Parch**: Number of parents/children aboard
- **Fare**: Passenger fare
- **Embarked**: Port of embarkation (C, Q, S)

This repository contains all the code and resources I used to tackle the problem.

---

## ğŸš€ Project Highlights

- **Data Preprocessing**: Handled missing data, transformed categorical variables, and scaled numerical features.
- **Feature Engineering**: Extracted additional insights from the existing features, such as family size and title extraction from names.
- **Model Selection**: Experimented with various models, including Logistic Regression, Random Forest, and XGBoost.
- **Evaluation**: Used cross-validation to ensure the robustness of the model.

---

## ğŸ“Š Results

Achieved a **Top 17% ranking** on the Kaggle leaderboard. My final model utilized a Logistic Regression approach to maximize accuracy on unseen data.

---


## ğŸŒŸ Next Steps

- Dive deeper into feature selection and engineering.
- Explore advanced ensemble techniques.
- Tackle more Kaggle competitions to refine my skills.

---

## ğŸ¤ Connect

If you have any feedback or want to collaborate on future projects, feel free to reach out via LinkedIn.

Happy coding! ğŸš€
